#PAT = Political analysis (of) Tweets - this file holds all methods for processing the ML on a csv file generated by main

import pandas as pd
from sklearn.metrics import confusion_matrix
from xgboost import XGBClassifier
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.feature_extraction import text
from sklearn.metrics import accuracy_score,recall_score,precision_score, confusion_matrix

def cleanMasterCSV(masterCSV):
    textLengths=[]
    masterDf = pd.read_csv(masterCSV)
    masterDf['subreddit'] = masterDf['subreddit'].map(lambda x: 1 if x == "democrats" else 0)
    masterDf = masterDf.drop(['selftext','link_flair_text'],axis=1).rename(columns={"title":"fullText"})
    for item in masterDf["fullText"]:
        textLengths.append(len(item))
    masterDf["textLength"]=textLengths

    print("CSV cleaned and ready for training")
    return masterDf

def baselines(masterDfCleaned):
    X = masterDfCleaned[['fullText', 'textLength']]
    y = masterDfCleaned['subreddit']
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)
    print("Baselines determined:")
    print(y_test.value_counts(normalize=True))

def textClassifierTest(masterDfCleaned,stopWords):
    X = masterDfCleaned[['fullText', 'textLength']]
    y = masterDfCleaned['subreddit']
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)


    pipe_cvec_lr = Pipeline([
        ('cvec', CountVectorizer()),
        ('lr', LogisticRegression())
    ])

    pipe_params_cvec_lr = {
        'cvec__max_features': [None, 500, 1000],
        'cvec__min_df': [2, 3],
        'cvec__max_df': [.3, .4, ],
        'cvec__ngram_range': [(1, 2), (1, 3)],
        'cvec__stop_words': [None, 'english', stopWords],
        'lr__penalty': ['l2']
    }

    gs = GridSearchCV(pipe_cvec_lr, param_grid=pipe_params_cvec_lr, cv=5, n_jobs=-1, verbose=1)

    gs.fit(X_train['fullText'], y_train)
    cvlr_bestscore = gs.best_score_
    cvlr_params = gs.best_params_
    cvlr_train = gs.score(X_train["fullText"], y_train)
    cvlr_test = gs.score(X_test["fullText"], y_test)
    cvlr = ('CountVec with LogReg', cvlr_bestscore, cvlr_params, cvlr_train, cvlr_test)
    print(f'Best CV Score: {gs.best_score_}')
    print(f'Best Parameters: {gs.best_params_}')
    print(f'Train Accuracy Score: {gs.score(X_train["fullText"], y_train)}')
    print(f'Test Accuracy Score: {gs.score(X_test["fullText"], y_test)}')

def textLRCVtest(masterDfCleaned,stopWords):
    # define features
    X = masterDfCleaned['fullText']
    y = masterDfCleaned['subreddit']

    # train test split
    X_train, X_test, y_train, y_test = train_test_split(X,
                                                        y,
                                                        stratify=y,
                                                        random_state=42)

    # instantiate countvectorizer
    cvec = CountVectorizer(stop_words=stopWords,
                           ngram_range=(1, 2), min_df=2,
                           max_features=None, max_df=0.4)
    # Fit our CountVectorizer on the training data and transform training data.
    X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).todense()
                                , columns=cvec.get_feature_names())

    # Fit our CountVectorizer on the test data and transform training data.
    X_test_cvec = pd.DataFrame(cvec.transform(X_test).todense()
                               , columns=cvec.get_feature_names())

    # instantiate logisticregression
    lr = LogisticRegression()
    # fit data
    lr = lr.fit(X_train_cvec, y_train)

    # score our logistic regression model on our fitted training data
    print("Training Score:")
    print(lr.score(X_train_cvec, y_train))

    # score our logistic regression model on our fitted testing data
    print("Testing Score:")
    print(lr.score(X_test_cvec, y_test))


    # generate predictions
    pred = lr.predict(X_test_cvec)

    # generate confusion matrix
    conf = confusion_matrix(y_test,  # True values.
                            pred)  # Predicted values.
    tn, fp, fn, tp = conf.ravel()

    # convert confusion matrix to dataframe
    df_lr = pd.DataFrame(conf, index=['actual republican', 'actual democrats'],
                         columns=['predicted republican', 'predicted democrats'])
    print(df_lr)

    params = lr.get_params()
    print("Final Paramerters:")
    print(params)


    return lr,cvec

def lrPredictor(lr,cvec, testData):
    print("Testing the sentence: \""+ testData[0]+"\"")
    dictMap = {0:"Republican", 1:"Democrat"}
    X_test_cvec = pd.DataFrame(cvec.transform(testData).todense()
                               , columns=cvec.get_feature_names_out())

    prediction = lr.predict(X_test_cvec)
    probability = lr.predict_proba(X_test_cvec)
    confidence = probability[0][prediction[0]]


    print("Predicted Political Alignment: "+dictMap.get(prediction[0]))
    print("Confidence: ", confidence)







def MLmain():
    additionalStopWords = ['www', 'things', 'does', 'x200b', 'amp',
                               'just', 'like', 'https', 'com', 'watch', 'want',
                               'says', 'say', 'did', 'this']

    stopWords = text.ENGLISH_STOP_WORDS.union(additionalStopWords)

    print("Cleaning Provided CSV for Learning...")
    masterDfCleaned = cleanMasterCSV('./data/masterDF.csv')
    print("Setting Parameters for Training and Determining Baselines...")
    baselines(masterDfCleaned)
    #print("Attempting Text Classification...")
    #textClassifierTest(masterDfCleaned,stopWords)
    print("Attempting Text Classification With LogisticRegression and CountVectorizer...")
    lr,cvec = textLRCVtest(masterDfCleaned,stopWords)

    lrPredictor(lr,cvec,["Enter test line here"])





if __name__ == "__main__":
    MLmain()